### model
model_name_or_path: OpenLeecher/story_gen_11
reward_model: https://5c3b-46-10-148-86.ngrok-free.app/get_rewards
reward_model_type: api

### method
stage: ppo
do_train: true
finetuning_type: lora
flash_attn: fa2
enable_liger_kernel: true
optim: adamw_8bit
bf16: true

### lora
lora_rank: 128
lora_alpha: 256
lora_dropout: 0.01
lora_target: all

### ddp
#ddp_timeout: 180000000
#deepspeed: examples/deepspeed/ds_z3_config.json

### data
dataset: story_dataset
dataset_dir: data
template: llama3
seed: 66
cutoff_len: 3072
preprocessing_num_workers: 16
use_fast_tokenizer: true

### output
output_dir: saves/full/story_gen_ppo
overwrite_output_dir: true
save_steps:  6
save_total_limit: 1
save_only_model: true

### logging
logging_steps: 1
report_to: wandb
run_name: StoryGen_PPO

### hub
push_to_hub: true
hub_private_repo: true
hub_model_id: story_gen_ppo
hub_strategy: every_save
hub_token: __HUB__TOKEN__PLACEHOLDER__

### train
per_device_train_batch_size: 8
gradient_accumulation_steps: 3
rollout_batch_size: 80
ppo_buffer_size: 10
ppo_whiten_rewards: true
ppo_score_norm: true
ppo_epochs: 3
ppo_target: 10
learning_rate: 0.000005
num_train_epochs: 1.0
lr_scheduler_type: polynomial
max_grad_norm: 1.0
warmup_steps: 0
weight_decay: 0.01

### eval
val_size: 0.05
per_device_eval_batch_size: 1
evaluation_strategy: steps
eval_steps: 40

### sample
repetition_penalty: 1.1
temperature: 0.7
top_p: 0.9
max_new_tokens: 2048
